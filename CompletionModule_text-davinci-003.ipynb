{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPEN AI PYTHON API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REFERED GEEKS FOR GEEKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = \"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\" #Get your own API key from the OpenAI website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function that takes in string argument as parameter\n",
    "\n",
    "Uses OpenAI's Completion module that helps execute any tasks involving text \n",
    "\n",
    "Model name used here is text-davinci-003 \n",
    "\n",
    "There are many other models available under the umbrella of GPT-3 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROMPT: This is the input string or prompt that you want the GPT-3 model to respond to.\n",
    "\n",
    "MaxToken: This parameter controls the maximum number of tokens (words or characters) in the generated output. The default value is set to 50.\n",
    "\n",
    "Outputs: This parameter specifies the number of output responses to generate in a single call. The default is set to 3.\n",
    "\n",
    "The function makes a call to the OpenAI Completion API using the openai.Completion.create method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def completion (PROMPT, MaxToken = 3000, outputs=3):\n",
    "    response = openai.Completion.create ( \n",
    "        model = \"text-davinci-003\",\n",
    "        prompt = PROMPT,\n",
    "        max_tokens = MaxToken,\n",
    "        n = outputs\n",
    "    )\n",
    "    # return response [\"choices\"][0]['text'].strip()\n",
    "    output = list()\n",
    "    for i in response[\"choices\"]:\n",
    "        output.append(i['text'].strip())\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROMPTS FOR TEXT GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Once upon a time, a brave turtle and a determined rabbit competed to reach a common goal. Despite their differences, they raced each other, pushing each other to reach a level of greatness they never knew they could attain. And through this challenging journey, they both achieved something marvelous.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROMPT = \"\"\"Write a story to inspire greatness, take the antagonist as a Rabbit and protagnist as turtle. Let antagonist and protagnist compete against each other for a common goal. Story should atmost have 3 lines in total.\"\"\"\n",
    "completion(PROMPT, MaxToken=3800, outputs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THE STRUCTURE OF THE RESPONSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <OpenAIObject text_completion id=cmpl-8VYiUp9rHtEQfr1Q5gFanHXenrngL at 0x1702a9f7470> JSON: {\n",
    "#   \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\",\n",
    "#   \"id\": \"cmpl-8VYiUp9rHtEQfr1Q5gFanHXenrngL\",\n",
    "#   \"object\": \"text_completion\",\n",
    "#   \"created\": 1702532310,\n",
    "#   \"model\": \"text-davinci-003\",\n",
    "#   \"choices\": [\n",
    "#     {\n",
    "#       \"text\": \"\\n\\nOnce upon a time a fast-moving Rabbit and a slow but determined Turtle set off to attain a common goal, determined to prove who could reach it first. Both worked hard and gave their best, eventually discovering that greatness sometimes found in the most unlikely of places.\",\n",
    "#       \"index\": 0,\n",
    "#       \"logprobs\": null,\n",
    "#       \"finish_reason\": \"stop\"\n",
    "#     }\n",
    "#   ],\n",
    "#   \"usage\": {\n",
    "#     \"prompt_tokens\": 45,\n",
    "#     \"completion_tokens\": 55,\n",
    "#     \"total_tokens\": 100\n",
    "#   }\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROMPTS FOR COMPLETION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Client: \"Well I don\\'t mean to be a pest, my good Sir, but I gotta tell ya\\', this bottle of wine is about as fresh as day-old soup!\" \\nBusinessman: \"Defy thy heart, young man, and but grant me this single boon, that it is not I who appears the fool, but that it be thyself, for thou pay\\'d the fee.\"']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROMPT = \"\"\"Write a short conversation between client and businessman about a wine bottle purchase. \n",
    "Client is not happy with the purchase and the businessman is not accepting his mistake. \n",
    "Make the conversation sarcastic. \n",
    "Each Response should have atmost 2 lines. \n",
    "The client should talk like Kevin Hart and businessman should talk like Shakespeare. \n",
    "\"\"\"\n",
    "completion(PROMPT, MaxToken=3000, outputs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Well, I can give you something else if you'd like. We have a selection of plant pots right now that would be great for water bottles. We just got them in stock this week!\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROMPT = \"\"\"Complete the below conversation between a client and a worker. \n",
    "Make the conversation have a wholesome plot twist. \n",
    "Conversation : ### \n",
    "Client: I want a water bottle. \n",
    "Worker: I don't have any water botlles. \n",
    "Client: But I want water bottles. \n",
    "Worker: \n",
    "### \n",
    "\"\"\"\n",
    "completion(PROMPT, MaxToken=3000, outputs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROMPTS FOR TRANSLATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tamil:\\nGeeks ‡Æï‡Æ≥‡Øç ‡Æï‡Æ≥‡Øç ‡Æ§‡Æ∞‡Æµ‡ØÅ ‡ÆÖ‡Æü‡Øç‡Æü‡Æµ‡Æ£‡Øà ‡ÆÖ‡ÆÆ‡Øç‡Æö‡ÆÆ‡Øç ‡ÆÖ‡Æ§‡Æø‡Æö‡ÆØ‡ÆÆ‡Ææ‡Æ©‡Æ§‡ØÅ.\\n\\nHindi:\\nGeeks ‡§ï‡•á ‡§ó‡•Ä‡§ï‡•ç‡§∏ ‡§ï‡•á ‡§°‡•á‡§ü‡§æ ‡§∏‡§Ç‡§∞‡§ö‡§®‡§æ ‡§ï‡•ã‡§∞‡•ç‡§∏ ‡§∏‡§∞‡•ç‡§µ‡§∂‡•ç‡§∞‡•á‡§∑‡•ç‡§† ‡§π‡•à‡•§']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROMPT = \"\"\" \n",
    "Translate the below text in Tamil and Hindi. \n",
    "Text:### \n",
    "Geeks for Geeks Data Structures Course is the best. \n",
    "### \n",
    "\"\"\"\n",
    "completion(PROMPT, MaxToken=3000, outputs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROMPTS FOR SUMMARIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In this story, a hare and a tortoise compete in a race. The hare is able to get a head start, but yells off guard and takes a nap, allowing the tortoise to slowly make progress and end up winning the race. The moral of the story is to not be arrogant in victory and remain humble.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROMPT = \"\"\" \n",
    "Summarize the below text and extract the key points. \n",
    "Text:### \n",
    "This is an extremely popular story about a hare and a tortoise. \n",
    "The hare is an animal that is known to move quickly, while a tortoise is one to move slowly. \n",
    "One day, the hare challenged the tortoise to a race simply to prove that he was the best. The tortoise agreed. \n",
    "Once the race began the hare was easily able to get a head start. Upon realizing that the tortoise is far behind. The overconfident hare decided to take a nap. \n",
    "Meanwhile the tortoise, who was extremely determined and dedicated to the race was slowly nearing the finish line. \n",
    "The tortoise won the race while the hare napped. Most importantly he did it with humility and without arrogance. \n",
    "### \n",
    "\"\"\"\n",
    "completion(PROMPT, MaxToken=3000, outputs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"- Farmer asked his son to take care of their herd of sheep\\n- Son got bored and started shouting ‚ÄúWolf! Wolf‚Äù, causing villagers to come help him \\n- Villagers got angry when they realized he was only joking\\n- On the next day the boy saw an actual Wolf and shouted for help but villagers didn't believe him\\n- Villagers were too angry to help after being fooled twice\"]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROMPT = \"\"\" \n",
    "Summarize the below text in bullet points. \n",
    "Text:### \n",
    "A farmer asked his son to take their herd of sheep grazing every day. \n",
    "While the boy watched over the sheep, he got bored and decided to have some fun. \n",
    "So, he shouted, ‚ÄúWolf! Wolf!‚Äù. Upon hearing this the villagers ran to help him chase the Wolf away. \n",
    "As they reached him, they realized that there was no Wolf and he was just kidding. \n",
    "The villagers were furious and they yelled at the boy for creating chaos and panic. \n",
    "On the next day and the boy shouted ‚ÄúWolf!‚Äù again and once again the villagers came to help him and saw that there was no wolf. \n",
    "This made them very angry again. \n",
    "On the same day, the boy saw an actual Wolf that has terrorizing the sheep. \n",
    "The boy cried ‚ÄúWolf! Wolf! please help me‚Äù and no villagers showed up as they believed that the boy was joking again. \n",
    "### \n",
    "\"\"\"\n",
    "completion(PROMPT, MaxToken=3000, outputs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROMPTS FOR RETRIEVING FACTUAL INFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The states and union territories of India are: \\n\\nStates: \\nAndhra Pradesh, Arunachal Pradesh, Assam, Bihar, Chhattisgarh, Goa, Gujarat, Haryana, Himachal Pradesh, Jammu and Kashmir, Jharkhand, Karnataka, Kerala, Madhya Pradesh, Maharashtra, Manipur, Meghalaya, Mizoram, Nagaland, Odisha, Punjab, Rajasthan, Sikkim, Tamil Nadu, Telangana, Tripura, Uttar Pradesh, Uttarakhand, West Bengal.\\n\\nUnion Territories: \\nAndamans and Nicobar Islands, Chandigarh, Dadra and Nagar Haveli, Daman and Diu, Delhi, Lakshadweep, Ladakh, Puducherry.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROMPT = \"\"\" \n",
    "What all states and union teritories are in India? \n",
    "\"\"\"\n",
    "completion(PROMPT, MaxToken=3000, outputs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROMPTS FOR TEXT CONVERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. üßô‚Äç‚ôÇÔ∏èüåà \n",
      "2. üé≤ü§ñ\n",
      "3. üëª\n"
     ]
    }
   ],
   "source": [
    "PROMPT = \"\"\" \n",
    "Convert the below movie titles in emojis \n",
    "Movies List:### \n",
    "1. Wizard of Oz \n",
    "2. The imitation game \n",
    "3. Ghosted \n",
    "### \n",
    "\"\"\"\n",
    "print(completion(PROMPT, MaxToken=3000, outputs=1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROMPTS FOR ENCODING AND DECODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. &#71;&#101;&#101;&#107;&#115; \n",
      "2. &#102;&#111;&#114; \n",
      "3. &#71;&#101;&#101;&#107;&#115;\n"
     ]
    }
   ],
   "source": [
    "PROMPT = \"\"\" \n",
    "Encode the below texts in only special characters \n",
    "Text:### \n",
    "1. Geeks \n",
    "2. for \n",
    "3. Geeks \n",
    "### \n",
    "\"\"\"\n",
    "print(completion(PROMPT, MaxToken=3000, outputs=1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Geeks \n",
      "2. For \n",
      "3. Geeks\n"
     ]
    }
   ],
   "source": [
    "PROMPT = \"\"\" \n",
    "Decode the below encodings in only special characters to text \n",
    "Encodings:### \n",
    "1. &#71;&#101;&#101;&#107;&#115; \n",
    "2. &#102;&#111;&#114; \n",
    "3. &#71;&#101;&#101;&#107;&#115;\n",
    "### \n",
    "\"\"\"\n",
    "print(completion(PROMPT, MaxToken=3000, outputs=1)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
