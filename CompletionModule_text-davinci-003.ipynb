{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPEN AI PYTHON API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REFERED GEEKS FOR GEEKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = \"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\" #Get your own API key from the OpenAI website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function that takes in string argument as parameter\n",
    "\n",
    "Uses OpenAI's Completion module that helps execute any tasks involving text \n",
    "\n",
    "Model name used here is text-davinci-003 \n",
    "\n",
    "There are many other models available under the umbrella of GPT-3 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROMPT: This is the input string or prompt that you want the GPT-3 model to respond to.\n",
    "\n",
    "MaxToken: This parameter controls the maximum number of tokens (words or characters) in the generated output. The default value is set to 50.\n",
    "\n",
    "Outputs: This parameter specifies the number of output responses to generate in a single call. The default is set to 3.\n",
    "\n",
    "The function makes a call to the OpenAI Completion API using the openai.Completion.create method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def completion (PROMPT, MaxToken = 3000, outputs=3):\n",
    "    response = openai.Completion.create ( \n",
    "        model = \"text-davinci-003\",\n",
    "        prompt = PROMPT,\n",
    "        max_tokens = MaxToken,\n",
    "        n = outputs\n",
    "    )\n",
    "    # return response [\"choices\"][0]['text'].strip()\n",
    "    output = list()\n",
    "    for i in response[\"choices\"]:\n",
    "        output.append(i['text'].strip())\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROMPTS FOR TEXT GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Once upon a time, a rabbit and a turtle set out to compete for a common goal. The rabbit, determined to reach the goal first, darted off with great speed. The turtle, plodding slowly but surely, never gave up, and eventually overtook the rabbit to reach the goal.']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROMPT = \"\"\"Write a story to inspire greatness, take the antagonist as a Rabbit and protagnist as turtle. Let antagonist and protagnist compete against each other for a common goal. Story should atmost have 3 lines in total.\"\"\"\n",
    "completion(PROMPT, MaxToken=3800, outputs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THE STRUCTURE OF THE RESPONSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <OpenAIObject text_completion id=cmpl-8VYiUp9rHtEQfr1Q5gFanHXenrngL at 0x1702a9f7470> JSON: {\n",
    "#   \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\",\n",
    "#   \"id\": \"cmpl-8VYiUp9rHtEQfr1Q5gFanHXenrngL\",\n",
    "#   \"object\": \"text_completion\",\n",
    "#   \"created\": 1702532310,\n",
    "#   \"model\": \"text-davinci-003\",\n",
    "#   \"choices\": [\n",
    "#     {\n",
    "#       \"text\": \"\\n\\nOnce upon a time a fast-moving Rabbit and a slow but determined Turtle set off to attain a common goal, determined to prove who could reach it first. Both worked hard and gave their best, eventually discovering that greatness sometimes found in the most unlikely of places.\",\n",
    "#       \"index\": 0,\n",
    "#       \"logprobs\": null,\n",
    "#       \"finish_reason\": \"stop\"\n",
    "#     }\n",
    "#   ],\n",
    "#   \"usage\": {\n",
    "#     \"prompt_tokens\": 45,\n",
    "#     \"completion_tokens\": 55,\n",
    "#     \"total_tokens\": 100\n",
    "#   }\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROMPTS FOR COMPLETION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Client: \"Yoohoo, I got some bad news for you! You sold me a janky old wine bottle, and expect me to drink it? It looks like it\\'s been through the ringer!\" \\nBusinessman: \"Assuredly, sir, though the vessel may be tarnished, the liquor within is unblemished and of superior caliber.\" \\nClient: \"Oh snap, you just tried to school me? We\\'ll see, old man. I\\'m still not payin\\' the full price!\"']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROMPT = \"\"\"Write a short conversation between client and businessman about a wine bottle purchase. \n",
    "Client is not happy with the purchase and the businessman is not accepting his mistake. \n",
    "Make the conversation sarcastic. \n",
    "Each Response should have atmost 2 lines. \n",
    "The client should talk like Kevin Hart and businessman should talk like Shakespeare. \n",
    "\"\"\"\n",
    "completion(PROMPT, MaxToken=3000, outputs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I may not have any water bottles, but I can offer you something even better - a reusable water bottle! It's the best way to stay hydrated, and it will help save our planet too.\"]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROMPT = \"\"\"Complete the below conversation between a client and a worker. \n",
    "Make the conversation have a wholesome plot twist. \n",
    "Conversation : ### \n",
    "Client: I want a water bottle. \n",
    "Worker: I don't have any water botlles. \n",
    "Client: But I want water bottles. \n",
    "Worker: \n",
    "### \n",
    "\"\"\"\n",
    "completion(PROMPT, MaxToken=3000, outputs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROMPTS FOR TRANSLATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tamil:\\nGeeks for Geeks தரவு அட்டவணைகள் பாடம் அதிசயமாக உள்ளது.\\n\\nHindi:\\nGeeks for Geeks डेटा संरचनाओं की कोर्स सबसे अच्छी है।']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROMPT = \"\"\" \n",
    "Translate the below text in Tamil and Hindi. \n",
    "Text:### \n",
    "Geeks for Geeks Data Structures Course is the best. \n",
    "### \n",
    "\"\"\"\n",
    "comp(PROMPT, MaxToken=3000, outputs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
